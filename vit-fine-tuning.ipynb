{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fine tuning and validation of VIT-Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import modal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "from transformers import ViTForImageClassification\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Modal setup\n",
    "stub = modal.App(\"vit-fairface-training\")\n",
    "\n",
    "# Define the image for Modal\n",
    "image = modal.Image.debian_slim().pip_install(\n",
    "    \"torch\",\n",
    "    \"torchvision\",\n",
    "    \"transformers\",\n",
    "    \"pandas\",\n",
    "    \"pillow\",\n",
    "    \"tqdm\",\n",
    "    \"pyarrow\",\n",
    "    \"accelerate\"\n",
    ")\n",
    "\n",
    "# Create volumes\n",
    "volume = modal.Volume.from_name(\"fairface-data\", create_if_missing=True)\n",
    "model_volume = modal.Volume.from_name(\"vit-models\", create_if_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class for FairFace\n",
    "class FairFaceDataset(Dataset):\n",
    "    def __init__(self, parquet_file, transform=None):\n",
    "        self.data = pd.read_parquet(parquet_file)\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        # Extract image bytes from the 'bytes' key in the dict\n",
    "        image = Image.open(io.BytesIO(row['image']['bytes'])).convert('RGB')\n",
    "        label = row['race']  # Adjust if your label column is different\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "def get_dataloaders(batch_size=32):\n",
    "    train_dataset = FairFaceDataset(\"/root/data/train.parquet\")\n",
    "    val_dataset = FairFaceDataset(\"/root/data/validation.parquet\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "def create_vit_model(num_classes):\n",
    "    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224',\n",
    "                                                     num_labels=num_classes,\n",
    "                                                     ignore_mismatched_sizes=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, accelerator, print_every=10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % print_every == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            accelerator.print(f\"Batch {batch_idx+1}/{len(train_loader)} - \"\n",
    "                              f\"Train Loss: {total_loss/(batch_idx+1):.4f}, \"\n",
    "                              f\"Train Acc: {100.*correct/total:.2f}%\")\n",
    "\n",
    "    return total_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "def validate(model, val_loader, criterion, accelerator, print_every=10):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            if (batch_idx + 1) % print_every == 0 or (batch_idx + 1) == len(val_loader):\n",
    "                accelerator.print(f\"Batch {batch_idx+1}/{len(val_loader)} - \"\n",
    "                                  f\"Val Loss: {total_loss/(batch_idx+1):.4f}, \"\n",
    "                                  f\"Val Acc: {100.*correct/total:.2f}%\")\n",
    "\n",
    "    return total_loss / len(val_loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@stub.function(\n",
    "    image=image,\n",
    "    gpu=\"A100\",  # Use 4 A100 GPUs\n",
    "    volumes={\"/root/data\": volume, \"/root/models\": model_volume},\n",
    "    timeout=14400\n",
    ")\n",
    "def train_model(num_epochs=10, batch_size=32, learning_rate=2e-5):\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator()\n",
    "    device = accelerator.device\n",
    "\n",
    "    train_loader, val_loader = get_dataloaders(batch_size)\n",
    "    num_classes = 7\n",
    "    model = create_vit_model(num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Prepare for distributed training\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        accelerator.print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, accelerator)\n",
    "        accelerator.print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, accelerator)\n",
    "        accelerator.print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            accelerator.save(model.state_dict(), \"/root/models/vit_fairface_best.pth\")\n",
    "            accelerator.print(f\"Saved new best model with validation accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    accelerator.save(model.state_dict(), \"/root/models/vit_fairface_final.pth\")\n",
    "    accelerator.print(\"\\nTraining completed!\")\n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 72.06%\n"
     ]
    }
   ],
   "source": [
    "with stub.run():\n",
    "    best_acc = train_model.remote(num_epochs=10, batch_size=16)\n",
    "    print(f\"Best validation accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
