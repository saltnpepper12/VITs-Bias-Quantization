# ğŸ§‘â€ğŸ¤â€ğŸ§‘ FairFace ViT/Swin Bias & Quantization Analysis ğŸ¤–

## ğŸ“š Project Description

This project investigates the impact of **INT8 quantization** on model bias and accuracy for Vision Transformer (ViT) and Swin Transformer models trained on the FairFace dataset. The workflow covers model training, ONNX export, post-training quantization, and systematic validation. The main aim is to compare the fairness and performance of baseline (FP32) and INT8-quantized models across demographic groups, using robust, reproducible pipelines on Modal cloud infrastructure.

## ğŸ—‚ï¸ Directory Structure & File Overview

```
.
â”œâ”€â”€ Final-output-CSV-Files/              # ğŸ“Š Validation results
â”‚   â”œâ”€â”€ VIT-INT8-Quantized-Validation.csv
â”‚   â”œâ”€â”€ Swin-INT8-Quantized-Validation.csv
â”‚   â”œâ”€â”€ Swin-Base-validation.csv
â”‚   â””â”€â”€ VIT-BASE-validation.csv
â”œâ”€â”€ model-files/                         # ğŸ§© Model files
â”‚   â”œâ”€â”€ base-model-onnx-files/
â”‚   â”‚   â”œâ”€â”€ vit_fairface_best.onnx
â”‚   â”‚   â””â”€â”€ swin_fairface_best.onnx
â”‚   â”œâ”€â”€ INT8-Model-Quantized-Files/
â”‚   â”‚   â”œâ”€â”€ swin_fairface_best_int8.onnx
â”‚   â”‚   â””â”€â”€ vit_quantized_model.onnx
â”‚   â””â”€â”€ base-model-pth-files/
â”‚       â”œâ”€â”€ swinv2_fairface_best.pth
â”‚       â””â”€â”€ vit_fairface_best.pth
â”œâ”€â”€ sample-test-pictures/                # ğŸ–¼ï¸ Sample images
â”‚   â””â”€â”€ [Sample images for quick testing]
â”œâ”€â”€ calibration_images/                  # ğŸ·ï¸ Calibration images
â”‚   â””â”€â”€ calib_XXX.jpg
â”œâ”€â”€ INT8-Quant-VIT-Swin.ipynb            # ğŸ“’ Quantization notebook
â”œâ”€â”€ validation-quantized-models.ipynb    # ğŸ“’ Validation notebook
â”œâ”€â”€ vit-fine-tuning.ipynb                # ğŸ“’ ViT fine-tuning
â”œâ”€â”€ swin-fine-tuning.ipynb               # ğŸ“’ Swin fine-tuning
â”œâ”€â”€ Swin-local-inference.ipynb           # ğŸ“’ Swin local inference
â”œâ”€â”€ vit-local-inference.ipynb            # ğŸ“’ ViT local inference
â”œâ”€â”€ export_swin_onnx.py                  # ğŸ“ Swin ONNX export script
â”œâ”€â”€ extract_calibration_images.py        # ğŸ“ Calibration image extraction
â”œâ”€â”€ modal_dataset.py                     # ğŸ“ Modal dataset utility
â””â”€â”€ __pycache__/
```

## ğŸ“ File & Folder Details

### ğŸ§© **Model Files**
- `model-files/base-model-pth-files/`: PyTorch checkpoints for the best ViT and Swin models (`.pth`).
- `model-files/base-model-onnx-files/`: Baseline (FP32) ONNX exports of the best models.
- `model-files/INT8-Model-Quantized-Files/`: INT8-quantized ONNX models for ViT and Swin.

### ğŸ·ï¸ **Calibration Images**
- `calibration_images/`: 100+ images used for static quantization calibration.

### ğŸ–¼ï¸ **Sample Test Images**
- `sample-test-pictures/`: Example images for quick inference and demo.

### ğŸ“Š **Output CSVs**
- `Final-output-CSV-Files/`: Validation results for all models, including top-1/top-5 predictions and probabilities.

### ğŸ“’ **Notebooks**
- `vit-fine-tuning.ipynb`: Fine-tuning ViT on FairFace, saving best `.pth` model.
- `swin-fine-tuning.ipynb`: Fine-tuning Swin on FairFace, saving best `.pth` model.
- `INT8-Quant-VIT-Swin.ipynb`: Quantization workflows for both ViT and Swin (static/dynamic, INT8).
- `validation-quantized-models.ipynb`: Validates quantized ONNX models, generates detailed CSVs.
- `vit-local-inference.ipynb`: Inference and validation for baseline ViT model.
- `Swin-local-inference.ipynb`: Inference and validation for baseline Swin model.

### ğŸ“ **Scripts**
- `export_swin_onnx.py`: Exports Swin PyTorch model to ONNX.
- `extract_calibration_images.py`: Extracts images from the dataset for calibration.
- `modal_dataset.py`: Modal utility for dataset management.

## ğŸš€ **How to Use**

1. **Train & Export Models:**  
   Use `vit-fine-tuning.ipynb` and `swin-fine-tuning.ipynb` to train and save `.pth` models.  
   Export to ONNX using `export_swin_onnx.py` or similar for ViT.

2. **Quantize Models:**  
   Use `INT8-Quant-VIT-Swin.ipynb` to quantize ONNX models to INT8 using calibration images.

3. **Validate & Analyze:**  
   Use `validation-quantized-models.ipynb` (and local inference notebooks) to run validation, generate CSVs, and compare accuracy and bias.

4. **Results:**  
   All validation results are in `Final-output-CSV-Files/`, with top-1/top-5 predictions and probabilities for each sample.

## ğŸ¯ **Project Aim**

The main goal is to **analyze and compare bias and accuracy between baseline and INT8-quantized ViT/Swin models** on the FairFace dataset, providing insight into the fairness and deployment-readiness of quantized vision transformers.

---

**For more details, see the individual notebooks and scripts.**  
Let us know if you need help running or extending the analysis! ğŸ˜Š
